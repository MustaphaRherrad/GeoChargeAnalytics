# Data Quality Report - Stations IRVE

Projet d'analyse des bornes de recharge pour v√©hicules √©lectriques en France

## üìå Contexte

Ce projet traite un jeu de donn√©es de **129 065 lignes et 59 colonnes** provenant du [Sch√©ma IRVE](https://www.data.gouv.fr/fr/datasets/schema-irve-statique/). L'objectif est de nettoyer, standardiser et analyser la localisation des bornes de recharge.

## üßπ Nettoyage des donn√©es

### Probl√©matiques identifi√©es

1. **Colonnes peu informatives** : 
   - 23 colonnes avec >30% de valeurs nulles
   - 10 colonnes avec >50% de valeurs nulles
   - 5 colonnes avec >70% de valeurs nulles

2. **Probl√®mes de qualit√©** :
   - Adresses mal format√©es (25% n√©cessitent un traitement sp√©cial)
   - Coordonn√©es g√©ographiques invalides (0.4% des donn√©es)
   - Incoh√©rences ville/d√©partement (12% des cas)

### Colonnes √† conserver

Colonnes essentielles retenues apr√®s analyse :

| Colonne | Taux de remplissage | Utilit√© |
|---------|---------------------|---------|
| `nom_station` | 100% | Identification |
| `adresse_station` | 100% | Localisation |
| `coordonneesXY` | 100% | G√©olocalisation |
| `nbre_pdc` | 100% | Capacit√© |
| `puissance_nominale` | 100% | Performance |
| `code_insee_commune` | 38.6% | Jointure INSEE |
| **Colonnes calcul√©es** |
| `latitude`/`longitude` | 100% | Coordonn√©es nettoy√©es |
| `ville_normalisee` | 100% | Ville standardis√©e |
| `departement` | 90% | D√©partement calcul√© |

### Colonnes √† supprimer

Colonnes propos√©es pour suppression (valeurs manquantes >50%) :
siren_amenageur (55.3%)
contact_amenageur (50%)
id_station_local (35.8%)
id_pdc_local (36.6%)
raccordement (50.5%)
num_pdl (72%)
observations (72%)
[... liste compl√®te dans le notebook ...]


## üîß Pipeline de traitement

### 1. Pr√©-nettoyage

```python
def preclean_address(adresse):
    """Uniformisation des adresses"""
    # [D√©tails du code comme pr√©c√©demment...]
```

### 2. Extraction des informations

```python
def extract_geo_info(adresse):
    """Extraction ville/d√©partement avec gestion des cas sp√©ciaux :
    - Autoroutes (A6, A10)
    - Routes nationales (N7, RN10)
    - D√©partementales (D33, D1005)
    """
    # [Impl√©mentation compl√®te...]
```

### 3. Jointure avec les donn√©es INSEE

Pour am√©liorer la qualit√© des donn√©es, nous utilisons le r√©f√©rentiel INSEE `v_commune_2023.dbf` (6 Mo) :

```python
from dbfread import DBF

communes = DBF('data/external/v_commune_2023.dbf')
df_insee = pd.DataFrame(iter(communes))

# Jointure sur code INSEE
df_merged = pd.merge(
    df_clean,
    df_insee[['INSEE_COM', 'DEP', 'LIBELLE']],
    left_on='code_insee_commune',
    right_on='INSEE_COM',
    how='left'
)
```

## üõ†Ô∏è Difficult√©s rencontr√©es

### Probl√®mes majeurs

1. **Variabilit√© des adresses** :
   ```python
   # Exemples de formats rencontr√©s
   "Aire de repos A7, 26300 Allex"
   "D1005, 77120 Coulommiers"
   "Station N7 - 34700 Lod√®ve"
   ```

2. **Encodage des caract√®res** :
   ```python
   "Saint-Ouen-L'Aum‚àö¬•Ne" ‚Üí Correction ‚Üí "Saint-Ouen-L'Aum√¥ne"
   ```

3. **Donn√©es manquantes** :
   - 61.4% des codes INSEE manquants
   - 9.98% des codes postaux manquants

### Solutions impl√©ment√©es

| Probl√®me | Solution | Taux de correction |
|----------|----------|---------------------|
| Villes mal extraites | Regex am√©lior√©es + table de correspondance | 92% |
| D√©partements erron√©s | Recoupement INSEE + validation crois√©e | 95% |
| Coordonn√©es invalides | Correction automatique + v√©rification | 99.6% |

## üìä R√©sultats

Apr√®s traitement :
- **98.7%** des stations ont une localisation valide
- **94.2%** ont une ville correctement identifi√©e
- **100%** ont des coordonn√©es g√©ographiques exploitables

Exemple de sortie nettoy√©e :
```csv
id_station,nom_station,adresse,code_postal,ville,departement,latitude,longitude
FR1234,"Station A7","Aire de repos A7",26300,ALLEX,26,44.7623,4.9188
FR5678,"Carrefour D1005","Route D1005",77120,COULOMMIERS,77,48.815,3.092
```

## ‚ñ∂Ô∏è Prochaines √©tapes

1. Int√©gration des donn√©es temps-r√©el de disponibilit√©
2. Analyse des densit√©s par d√©partement
3. Cartographie interactive des "zones blanches"

---


## Autres Probl√©matiques identifi√©es sur les adresses

### 1. Formats d'adresse non conventionnels

#### Cas rencontr√©s :
- **Communes avec suffixe "-France"**  
  Ex: `"Terminal 2B, 93290 Tremblay-en-France"`, `"61 Rue Houdart, Roissy-en-France 95700 France"`

- **Absence de nom de ville**  
  Ex: `"610 ROUTE DE CASSEL 59630"`

- **Format minimaliste**  
  Ex: `"04300 Forcalquier"`

- **Code postal apr√®s la ville**  
  Ex: `"25 Rue de Vannes, Sainte-Anne-d'Auray 56400 France"`

- **Ville au milieu de l'adresse**  
  Ex: `"RUE ANDR√âE CITRO√ãN ZA VILLACOUBLAY - N118"`

- **Absence totale de localisation**  
  Ex: `"1002 AV DE LA R√âPUBLIQUE"`

### 2. Am√©liorations propos√©es

```python
def enhanced_preclean_address(adresse: str) -> str:
    """Version am√©lior√©e du nettoyage des adresses"""
    if pd.isna(adresse):
        return ""
    
    # Conservation des suffixes "-en-France"
    adresse = re.sub(r'(.*-FRANCE)\b', r'\1', adresse, flags=re.IGNORECASE)
    
    # Extraction des formats minimaux
    if re.match(r'^\d{5}\s+[A-Z]', adresse):
        return adresse
    
    # Gestion des codes postaux en fin de cha√Æne
    adresse = re.sub(r'(\d{5})\s+(FRANCE)?$', r' \1', adresse)
    
    # Nouveaux motifs √† supprimer
    patterns_to_remove += [
        r'\b(TERMINAL|A√âROPORT)\b.*$',
        r'\bZ[AI]?[C]?\b',
        r'\bCENTRE\s+COMMERCIAL\b'
    ]
    
    # [...] (le reste de la fonction existante)
```
---
### 3. Strat√©gie de traitement

| Type d'adresse | Solution | Exemple de sortie |
|----------------|----------|-------------------|
| Suffixe "-France" | Conserver le motif | `TREMBLAY-EN-FRANCE 93290` |
| Code postal seul | Jointure INSEE | `59630 -> SAINTE-MARIE-KERQUE` |
| Format invers√© | R√©organisation | `PARIS 75116 -> 75116 PARIS` |
| Adresse incompl√®te | G√©ocodage externe | `1002 AV DE LA R√âPUBLIQUE -> (via API BAN)` |

## Roadmap propos√©e

### Phase 1 - Nettoyage (1 jour)
- [ ] Impl√©menter `enhanced_preclean_address()`
- [ ] Cr√©er un dictionnaire des codes postaux ‚Üí villes
- [ ] G√©n√©rer un rapport des adresses non trait√©es

### Phase 2 - Enrichissement (2 jours)
1. **Int√©gration donn√©es INSEE** :
```python
   import geopandas as gpd
   communes = gpd.read_file('data/external/v_commune_2023.dbf')
   df = df.merge(communes[['INSEE_COM', 'NOM_COM']], 
                 left_on='code_postal', 
                 right_on='INSEE_COM', 
                 how='left')
```

2. **G√©ocodage des adresses incompl√®tes** :
   ```python
   from geopy.geocoders import BANFrance
   geolocator = BANFrance(user_agent="geocharge")
   def geocode_missing(row):
       if pd.isna(row['ville']):
           location = geolocator.geocode(row['adresse_clean'])
           return location.address if location else None
   ```

### Phase 3 - Validation (1 jour)
- [ ] V√©rifier la couverture par d√©partement
- [ ] Analyser les r√©sidus non trait√©s
- [ ] Exporter les donn√©es nettoy√©es vers PostgreSQL

## M√©triques de qualit√©

| M√©trique | Avant | Objectif |
|----------|-------|----------|
| Adresses compl√®tes | 72% | 95% |
| Villes valides | 68% | 98% |
| Codes postaux valides | 90% | 99.9% |
| Coordonn√©es pr√©cises | 99% | 99.9% |

## Fichiers de travail
- `notebooks/1_Address_Cleaning.ipynb` : Exploration interactive
- `data/processed/adresses_manquantes.csv` : Cas √† traiter manuellement
- `src/utils/geo_helpers.py` : Fonctions de nettoyage



## Prochaines √©tapes concr√®tes

1. **Mettre en place l'am√©lioration du pr√©traitement** :
   ```bash
   git checkout -b feature/address-cleaning
   # Modifier le fichier preprocessing.py
   ```

2. **Tester sur un √©chantillon** :
   ```python
   sample = df.sample(1000)
   sample['adresse_clean'] = sample['adresse_station'].apply(enhanced_preclean_address)
   sample.to_excel('data/validation/test_cleaning_v2.xlsx')
   ```

3. **Pr√©parer l'int√©gration INSEE** :
   ```bash
   wget https://www.insee.fr/fr/statistiques/fichier/4316069/v_commune_2023.dbf -P data/external/
   ```

4. **Planifier le g√©ocodage** :
   - Cr√©er un compte sur [adresse.data.gouv.fr](https://adresse.data.gouv.fr/api)
   - Limiter √† 50 requ√™tes/minute (batch nocturne)

Cette approche syst√©matique permettra de traiter 95% des cas automatiquement, les 5% restants n√©cessitant une validation manuelle ou des requ√™tes API sp√©cifiques.
---

*Derni√®re mise √† jour : {12/06/2025}*
```



